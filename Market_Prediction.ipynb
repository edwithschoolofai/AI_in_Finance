{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Intro \n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/09/AI_applications_in_financial_services-565x613.png \"Logo Title Text 1\")\n",
    "\n",
    "- 금융 산업은 리스크를 싫어한다는 편견과 달리 인공지능 적용의 선두 주자였습니다.\n",
    "- 은행은 인적 자본 비용을 최소화시키면서 동시에 늘어나는 준법규정 요구를 맞추기 위해서 인공지능을 이용하기 시작했습니다.\n",
    "- 시티그룹 추정으로는, 가장 큰 은행이 준법감시인 수를 두 배로 늘렸는데 연간 2700 억의 비용이 들며, 이는 운영 경비의 10 %에 달합니다.\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/10/AI_solution_deployment_blog_96_dpi-565x454.png \"Logo Title Text 1\")\n",
    "\n",
    "- 비용 절감은 해외 대체인력 영입에 관한 것이 아닙니다. 이제 자동화에 관한 것입니다.\n",
    "- 현존 세계 데이터의 90 % 는 지난 2 년간 수집된 것입니다. 아주 좋은 시점이죠. \n",
    "- 데이터 입력 및 거래 처리와 같은 리소스 집약적이고 반복적인 작업은 자동화 및 인공지능에 매우 적합합니다. \n",
    "- 대기업과 스타트업의 CFO는 인공지능을 사용하여 핀테크를 개선시키기 위해 인공지능을 사용하는 방법을 찾아야 합니다. (계획, 예산 및 예측, 재무 보고, 운영 회계, 할당 및 조정, 화해, 회사 간 거래)\n",
    "\n",
    "![alt text](https://bluenotes.anz.com/content/dam/bluenotes/images/articles/2016/June/sibsonrizzo_ai-bakermckenzie_infog2.png/_jcr_content/renditions/original \"Logo Title Text 1\")\n",
    "\n",
    "### Research and Markets 에 따르면 금융 서비스 분야의 인공지능 시장은 2017 년 13 억 개에서 2022 년 74 억 개로 연평균 40.4 % 성장할 것으로 예상됩니다. \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*jsmP9AHF5c7_vBaFLpefsQ.png \"Logo Title Text 1\")\n",
    "\n",
    "## 인공지능을 합치는 데 발생하는 문제들\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/02/barriers_to_digital_transformation_banking-565x443.png \"Logo Title Text 1\")\n",
    "\n",
    "- 전통 시스템과의 소통 문제\n",
    "- 개인 정보 보호 이슈\n",
    "- 데이터 사일로 (Data silos)\n",
    "- 숙련된 직원의 부재 \n",
    "- 지도학습을 위한 수작업 처리\n",
    "- 문화의 부재 \n",
    "- 머신러닝의 잠재적인 편견 위험\n",
    "- 의사결정 어려움 : 클라우드 업체를 사용해야 하는 지, 직접 만들어야 하는지, 오픈 소스를 사용할 것인지 또는 조합할 것인지 등\n",
    "\n",
    "![alt text](https://dashbouquet.com/assets/img/blog/AI-in-FinTech-Market-Map-Image.png \"Logo Title Text 1\")\n",
    "\n",
    "## 적용 사례 \n",
    "\n",
    "![alt text](https://qph.fs.quoracdn.net/main-qimg-fcb631ba245b7d74fab2f851fba7093d-c \"Logo Title Text 1\")\n",
    "\n",
    "#### 보안 향상 \n",
    "\n",
    "![alt text](https://d279iyy6fmg6l4.cloudfront.net/blog/fraud-detection-in-banking.png \"Logo Title Text 1\")\n",
    "\n",
    "- 사기 행위, 의심스러운 거래, 미래 잠재적인 공격. 이를 어떻게 예방할 것인가?\n",
    "- 인공지능은 많은 양의 보안 데이터를 분석할 수 있으며, 회사가 성장하여 커져도 대응할 수 있습니다.\n",
    "- 회사들의 가치있는 데이타들이 온라인에 많이 올라와있으며 점점 더 많아질 것입니다. \n",
    "- 머신러닝을 사용하면, 시스템은 비정상 활동 또는 동작을 탐지하고 보안 팀에 보고할 수 있습니다. \n",
    "- 보안이 침해될 수 있는 방법은 무수히 많기 때문에,  \"진짜로 학습할 수 있는\" 시스템은 5 ~ 10 년 후에는 필수적이게 될 것입니다. \n",
    "- 리서치 회사인 Javelin Strategy의 2015 년 조사에 따르면, 오탐지로 인한 거부, 즉 합법적인 거래가 잘못 거부된 경우에 의한 소매업의 손실은 118 억에 달했습니다. \n",
    "- 오탐지로 인한 거부의 3 분의 1이 고객 손실을 초래하며, 미국의 경우, 실제 사기의 13 배에 달하는 피해를 입힙니다.\n",
    "- 다양한 데이터를 분석함으로써, 머신러닝 알고리즘은 실시간 승인의 정확도를 높이고 오탐지 거부를 줄이면서 인간 분석가가 놓치는 사기 거래를 탐지 할 수 있습니다. \n",
    "\n",
    "![alt text](https://newsroom.mastercard.com/wp-content/uploads/2016/11/MasterCard-decision-intelligence-infographic.V.6_TwitterCards.png \"Logo Title Text 1\")\n",
    "\n",
    "- Mastercard 회사가 결정 지능 (DI) 기술을 최근 출시하였습니다. \n",
    "- DI 는 사전 정의 규칙으로 한정짓지 않고, 구매 기록과 카드 소지자의 소비 습관으로부터 패턴을 수집하여 각각의 새로운 거래를 비교하고 점수를 매겨 행동 기준선을 설정합니다.\n",
    "\n",
    "![alt text](https://gigaom.com/wp-content/uploads/sites/1/2013/03/siftscience.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Sift Science 회사는 이상 금융거래 탐지 솔루션이 배치된 6,000 개 이상의 웹사이트에서 데이터를 수집합니다. \n",
    "- 이는 다중 채널 및 장치에서 데이터를 추적하고 분석할 수 있게 해줍니다.\n",
    "\n",
    "#### 처리 시간 줄이기\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*MfGMH7gnYgFd_NrLIUC7gA.png \"Logo Title Text 1\")\n",
    "\n",
    "- 영수증과 기타 금융 서류를 처리하는 것은 많은 시간을 요합니다.; \n",
    "- 여러 자원의 인내가 필요하며 인간의 실수가 자주 발생하는 필수 작업 중 하나입니다.\n",
    "- https://www.parascript.com/receipt-capture/ 가 이런 일을 합니다.\n",
    "\n",
    "#### 트레이딩 \n",
    "\n",
    "![alt text](http://www.turingfinance.com/wp-content/uploads/2013/11/Algorithmic-Trading-Systems-Conceptual.png \"Logo Title Text 1\")\n",
    "\n",
    "- 알고리즘 트레이딩은 매우 빠른 트레이딩 결정을 내리는 복잡한 인공지능을 사용합니다.(70 년대부터 시작)\n",
    "- 하루에 수천 또는 수백만 개의 거래를 하는 알고리즘 시스템은 고빈도거래 (HFT)라 불리며, 알고리즘 트레이딩 중 하나입니다.\n",
    "- 대부분의 헤지 펀드와 금융 기관은 트레이딩에 대한 그들의 인공지능 적용 방식을 공개하지 않지만 (그럴만 하죠), 머신러닝과 딥러닝은 실시간 의사결정의 길잡이로 점점 더 중요한 역할을 하고 있습니다 \n",
    "- 주식 시장은 티커심볼과는 아무런 연관이 없는 무수히 많은 인간 관련 요인에 따라 움직입니다. 그리고 머신러닝이 새로운 추세를 발견하고 신호를 알려줌으로써 금융 활동의 인간 \"직관\"을 복제하고 향상시킬 것을 바라고 있습니다.\n",
    "- 인공지능을 사용하는 유명한 헤지펀드는 다음과 같습니다 - Two Sigma, LLC, PDT Partners, DE Shaw, Man AHL, Citadel, Vatic Labs, Point72, Cubist etc.\n",
    "\n",
    "![alt text](https://cdn.sentient.ai/wp-content/uploads/2015/11/Creating_Genes_Slide_01.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- 샌프란시스코에 본사를 둔 헤지펀드를 운영하는 인공지능 회사인 Sentient Technologies는 수백만 개의 데이터를 수집하여 트레이딩 패턴을 찾고 추세를 예측하여 성공적인 주식 트레이딩 결정을 도와주는 알고리즘을 만들었습니다.\n",
    "- Sentient는 온라인에서 사용 가능한 방대한 양의 공개 데이터로부터 만들어진 수많은 시뮬레이션 트레이딩 시나리오를 실행합니다. \n",
    "- 몇 분 안에 1,800 일의 트레이딩을 압축합니다. \n",
    "- genes라고 불리는 성공적인 트레이딩 전략은 실시간 트레이딩으로 검증하여 자율적으로 경험을 쌓고 발전합니다.\n",
    "\n",
    "![alt text](https://s3.fintastico.com/media/CACHE/images/numerai-screenshot_756/507ca3ac16b727303ec3f180bd343adf.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Numerai는 인공지능을 사용하여 트레이딩 결정을 내립니다.\n",
    "- 알고리즘을 자체적으로 개발하는 대신에, 수 천명의 익명 데이터 사이언티스트들에게 작업을 소상하며 그들은 최고의 알고리즘을 만들어 암호화폐를 얻기 위해 경쟁합니다. \n",
    "- 이들은 데이터 사이언티스트들이 더 나은 모델을 구축하되, 펀드의 거래를 복제하지 못하도록 트레이딩 데이터를 공유합니다.\n",
    "\n",
    "#### 신용 대출\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/richardharris-feedzai-161117114315/95/using-machine-learning-ai-to-enhance-fraud-detection-21-638.jpg?cb=1479383034 \"Logo Title Text 1\")\n",
    "\n",
    "- 머신러닝 알고리즘은 수 백만 개의 소비자 데이터(나이, 직업, 결혼 여부, 등)와 금융 대출 혹은 보험 결과(이 사람이 대출을 정시 상환하였는지, 교통 사고를 당했는지 등) 데이터로부터 학습할 수 있습니다.\n",
    "- 추세는 미래의 대출과 보험에 영향을 미칠 수 있는 추세를 감지하기 위해 연속적으로 분석될 수 있습니다. (특정 주에서 교통 사고를 당한 젊은 사람들이 점점 더 많아지나요? 지난 15 년 동안 인구 통계상 특정 인구가 증가하고 있나요?) \n",
    "- 전통 시스템은 거래 내역, 신용 내역, 연간 소득 증가와 같은 과거 데이터를 사용하여 대출 연장과 관련된 위험을 인지하였습니다. \n",
    "- 이런 방식은 과거 데이터가 항상 미래 행동을 예측하는 표준이 되지는 않기 때문에 일관된 추정을 할 수 없습니다.\n",
    "- 머신러닝은 최근 거래, 시장 상황과 심지어 최신 뉴스를 사용한 실시간 데이터 분석을 진행해 신용 대출의 잠재적 위험을 감지할 수 있습니다. \n",
    "- 예측 분석의 도움으로 머신러닝 알고리즘은 petabytes 단위의 데이터를 분석해 사소한 행동을 이해하고 당사자의 행동을 평가하며 분석하여 가능한 사기를 탐지할 수 있습니다.\n",
    "- 이는 인간 투자자가 손으로 할 수는 없는 일입니다.\n",
    "- Zestfinance는 이런 일을 할 수 있습니다. https://www.zestfinance.com/zaml \n",
    "\n",
    "#### 포트폴리오 관리 \n",
    "\n",
    "![alt text](https://blogs.thomsonreuters.com/financial-risk/wp-content/uploads/sites/12/2017/12/1-What-wealth-managers-need-to-know-about-AI-12-Dec-17.gif \"Logo Title Text 1\")\n",
    "\n",
    "- robo-advisor라는 용어는 5 년 전만해도 없는 말이었지만, 지금은 금융 환경에서 흔히 볼 수 있습니다. \n",
    "- 이는 사용자의 위험 허용치와 목표에 맞게 금융 포트폴리오를 조정하는 알고리즘입니다.\n",
    "- 사용자들은 그들의 목표(예를 들면, 65 세에 250,000 달러의 저축으로 퇴직), 연령, 소득 그리고 현재 금융 자산을 입력합니다. \n",
    "- robo-advisor는 사용자의 목표에 도달하기 위해 자산 클래스와 금융 상품에 분산 투자합니다.\n",
    "- 그 후에 시스템은 사용자의 원래 목표에 가장 잘 맞도록 사용자의 목표의 변화와 시장의 실시간 변화에 따라 조정합니다. \n",
    "- robo-advisors는 편안한 투자를 느끼기 위해 직접 대면으로 투자자와 접촉하지 않으려하는 밀레니얼 세대 소비자들로부터 큰 지지를 받았습니다.\n",
    "- 마찬가지로, 인공지능화 가능한 지능형 금융어플은 소비자가 재무 관리, 소비 분석, 세금 양식 제출 자동화 그리고 투자 비용을 발생시키지 않는 사업 모델의 금융 추천을 돕고 있습니다.\n",
    "- Responsive.ai 는 이런 일을 합니다. http://alpha.responsive.ai/ \n",
    "\n",
    "## 이론 \n",
    "\n",
    "### 사용할 데이터\n",
    "\n",
    "- 회사에 대한 트윗(좋음/나쁨)\n",
    "- 레딧 포스트(좋음/나쁨)\n",
    "- 회사에 대한 (좋음/나쁨) \n",
    "- 과거 주가\n",
    "- 모든 종류의 소셜 미디어, 블로그 글\n",
    "- 모든 종류의 금융 메타 데이터(배당금, 금융 리포트, 등) \n",
    "\n",
    "#### 회귀 문제 vs 분류 문제? \n",
    "\n",
    "![alt text](https://searchengineland.com/figz/wp-content/seloads/2016/07/class-regress.png \"Logo Title Text 1\")\n",
    "\n",
    "- 회귀 모델로 생각할 수 있습니다. 즉, 시계열의 다음 데이터는 무엇인가요? \n",
    "- 분류 모델로도 생각할 수 있습니다. 즉, 주가가 내일 오를까? 내릴까? 혹은 살까? 말까? \n",
    "- 회귀 문제로 생각하길 원한다면 하나의 데이터를 사용해 가장 잘 맞는 선을 만듭니다\n",
    "- 여러 데이터를 사용하길 원한다면 수치 데이터를 사용해 다변수 회귀 모델을 만듭니다.\n",
    "- 하나의 데이터를 사용해 분류 모델을 사용하길 원한다면 입력(특정 날짜의 트윗, 포스트, 코멘트)과 출력(좋음/나쁨)간의 매핑을 학습하기만 하면 됩니다. 특정 날짜에 스택에 대한 감정의 대부분이 좋았거나 나쁘다고 말할 수 있습니다. 따라서 모든 날짜에 대해, 우리 알고리즘은 주식이 잘 되었는지 아닌지를 전반적으로 배울 것입니다. 그러면 새로운 날짜에 좋을지 나쁠지 분류할 수 있습니다. \n",
    "- 감정과 주가와 같은 수치 데이터를 합치길 원한다면 수치 데이터에 특정 날짜에 대한 전체적인 감정을 0/1로 분류하여 새로운 특징으로 추가합니다.\n",
    "\n",
    "### 선형 회귀 \n",
    "\n",
    "- 선형 회귀 선은 다음과 같은 방정식으로 나타낼 수 있습니다. Y = a + bX, 여기서 X는 설명 변수이며 Y는 의존 변수입니다. 선의 기울기는 b이며 a는 y절편입니다. (x = 0일 때 y값).\n",
    "\n",
    "![alt text](http://developer.rhino3d.com/images/linear-regression-01.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "prices = datasets.load_boston()\n",
    "\n",
    "# Use only one feature\n",
    "prices_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "prices_X_train = prices_X[:-20]\n",
    "prices_X_test = prices_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "prices_y_train = prices.target[:-20]\n",
    "prices_y_test = prices.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.SupportVectorMachine()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(prices_X_train, prices_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "prices_y_pred = regr.predict(prices_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*6zJ2ZUUPIOC8nhGqTr3yBQ.jpeg  \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/kMLl-TKaEnc/maxresdefault.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets,\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "- A forecast predicts future events.\n",
    "\n",
    "- A reinforcement learning agent optimizes future outcomes.\n",
    "\n",
    "https://doctorj.gitlab.io/sairen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('sairen-v0')\n",
    "for i_episode in xrange(20):\n",
    "    observation = env.reset()\n",
    "    for t in xrange(100):\n",
    "        env.render()\n",
    "        print observation\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print \"Episode finished after {} timesteps\".format(t+1)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
