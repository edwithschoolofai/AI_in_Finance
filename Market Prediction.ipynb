{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Intro \n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/09/AI_applications_in_financial_services-565x613.png \"Logo Title Text 1\")\n",
    "\n",
    "- 금융 산업은 위험을 싫어한다는 편견과 달리 인공지능 적용의 선두 주자였습니다.\n",
    "- 은행은 인적 자본 비용을 최소화시키면서 동시에 늘어나는 규제 준수 요구를 맞추기 위해서 인공지능을 이용하기 시작했습니다.\n",
    "- 시티은행이 추정한 바로는 가장 큰 은행이 규정 준수 업무를 위해 직원 수를 두 배로 늘렸는데, 은행 업계에 연간 2700 억의 비용을 지불하였고 이는 운영 경비의 10 %에 달하는 양이었습니다.\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/10/AI_solution_deployment_blog_96_dpi-565x454.png \"Logo Title Text 1\")\n",
    "\n",
    "- 비용 절감은 노동 중재 및 해외 고용에 관한 것이 아닙니다. 이제 자동화에 관한 것입니다.\n",
    "- 현존 세계 데이터의 90 % 는 지난 2 년간 수집된 것입니다. 이보다 더 좋았던 적은 없습니다. \n",
    "- 데이터 입력 및 거래 처리와 같은 리소스 집약적이고 반복적인 작업은 자동화 및 인공지능에 매우 적합합니다. \n",
    "- 대기업과 스타트업의 CFO는 인공지능을 사용하여 핀테크를 개선시키기 위해 인공지능을 사용하는 방법을 찾아야 합니다. (계획, 예산 및 예측, 재무 보고, 운영 회계, 할당 및 조정, 화해, 회사 간 거래)\n",
    "\n",
    "![alt text](https://bluenotes.anz.com/content/dam/bluenotes/images/articles/2016/June/sibsonrizzo_ai-bakermckenzie_infog2.png/_jcr_content/renditions/original \"Logo Title Text 1\")\n",
    "\n",
    "### Research and Markets 에 따르면 금융 서비스 분야의 인공지능 시장은 2017 년 13 억 개에서 2022 년 74 억 개로 연평균 40.4 % 성장할 것으로 예상됩니다. \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*jsmP9AHF5c7_vBaFLpefsQ.png \"Logo Title Text 1\")\n",
    "\n",
    "## 인공지능을 합치는 데 발생하는 문제들\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/02/barriers_to_digital_transformation_banking-565x443.png \"Logo Title Text 1\")\n",
    "\n",
    "- 전통 시스템과의 소통 문제\n",
    "- 개인 정보 보호 이슈\n",
    "- 데이터 사일로 (Data silos)\n",
    "- 숙련된 직원의 부재 \n",
    "- 지도 모델 학습에 필요한 수고\n",
    "- 문화적 정렬의 어려움 \n",
    "- 기계학습의 잠재적인 편향\n",
    "- 클라우드 공급 업체를 사용할 것인지, 내부적으로 구현할 것인지, 오픈 소스를 사용할 것인지 또는 독점할 것인지?\n",
    "\n",
    "![alt text](https://dashbouquet.com/assets/img/blog/AI-in-FinTech-Market-Map-Image.png \"Logo Title Text 1\")\n",
    "\n",
    "## 적용 사례 \n",
    "\n",
    "![alt text](https://qph.fs.quoracdn.net/main-qimg-fcb631ba245b7d74fab2f851fba7093d-c \"Logo Title Text 1\")\n",
    "\n",
    "#### 보안 향상 \n",
    "\n",
    "![alt text](https://d279iyy6fmg6l4.cloudfront.net/blog/fraud-detection-in-banking.png \"Logo Title Text 1\")\n",
    "\n",
    "- 사기적인 행동, 의심스러운 거래, 잠재적인 미래 공격. 이를 어떻게 완화시킬 것인가?\n",
    "- 인공지능은 많은 양의 보안 데이터를 분석하고 성장하는 회사의 규모에 맞게 조율할 수 있습니다.\n",
    "- 수많은 가치있는 회사들이 온라인에 산재해있으며 점점 더 많아질 것입니다. \n",
    "- 기계학습을 사용하여 시스템은 독특한(이상한) 활동 또는 동작을 감지하고 보안 팀에 플래그를 지정할 수 있습니다. \n",
    "- 보안이 침해될 수 있는 방법이 셀 수 없이 많기 때문에, 진짜로 "학습"하는 시스템은 5 년에서 10 년 후에 필수적이게 될 것입니다. \n",
    "- 리서치 회사인 Javelin Strategy의 2015 년 조사에 따르면, 위조된 거부, 즉 합법적인 거래가 잘못 거부된 경우에 의한 소매업의 손실은 118 억에 달했습니다. \n",
    "- 위조된 거부의 3 분의 1은 고객 손실을 초래하며, 오직 미국만이 실제 사기의 13 배에 달하는 피해를 입힙니다.\n",
    "- 다양한 데이터를 분석함으로써, 기계학습 알고리즘은 실시간 승인의 정확도를 높이고 위조된 거부를 줄이면서 인간 분석가가 놓치는 사기 거래를 탐지 할 수 있습니다. \n",
    "\n",
    "![alt text](https://newsroom.mastercard.com/wp-content/uploads/2016/11/MasterCard-decision-intelligence-infographic.V.6_TwitterCards.png \"Logo Title Text 1\")\n",
    "\n",
    "- Mastercard 회사가 결정 지능 (DI) 기술을 최근 출시하였습니다. \n",
    "- DI 는 사전에 정의된 규칙으로 자신을 제한하는 대신, 구매 기록과 카드 소지자의 소비 습관으로부터 패턴을 수집하여 각각의 새로운 거래를 비교하고 점수를 매겨 행동 기준선을 설정합니다.\n",
    "\n",
    "![alt text](https://gigaom.com/wp-content/uploads/sites/1/2013/03/siftscience.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Sift Science 회사는 이상 금융거래 탐지 솔루션이 배치된 6,000 개 이상의 웹사이트에서 데이터를 수집합니다. \n",
    "- 이는 다중 채널 및 장치에서 데이터를 추적하고 분석할 수 있게 해줍니다.\n",
    "\n",
    "#### 처리 시간 줄이기\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*MfGMH7gnYgFd_NrLIUC7gA.png \"Logo Title Text 1\")\n",
    "\n",
    "- 영수증과 기타 금융 서류를 처리하는 것은 많은 시간을 요합니다.; \n",
    "- 여러 자원의 인내가 필요하며 인간의 실수가 자주 발생하는 필수 작업 중 하나입니다.\n",
    "- https://www.parascript.com/receipt-capture/ 가 이런 일을 합니다.\n",
    "\n",
    "#### 트레이딩 \n",
    "\n",
    "![alt text](http://www.turingfinance.com/wp-content/uploads/2013/11/Algorithmic-Trading-Systems-Conceptual.png \"Logo Title Text 1\")\n",
    "\n",
    "- 알고리즘 트레이딩은 매우 빠른 트레이딩 결정을 내리는 복잡한 인공지능을 사용합니다.(70 년대부터 시작)\n",
    "- 하루에 수천 또는 수백만 개의 거래를 하는 알고리즘 시스템은 "고주파 거래" (HFT)라 불리며, 알고리즘 트레이딩 중 하나입니다.\n",
    "- 대부분의 헤지 펀드와 금융 기관은 트레이딩에 대한 그들의 인공지능 적용 방식을 공개하지 않지만 (좋은 이유로), 기계학습과 딥러닝은 실시간으로 거래 결정을 교정하는 데 점점 더 중요한 역할을 하고 있습니다 \n",
    "- 주식 시장은 티커심볼과는 아무런 연관이 없는 무수히 많은 인간 관련 요인에 따라 움직입니다. 그리고 기계학습이 새로운 추세를 발견하고 신호를 알려줌으로써 금융 활동의 인간 "직과"을 복제하고 향상시킬 것을 바라고 있습니다.\n",
    "- 인공지능을 사용하는 유명한 헤지펀드는 다음과 같습니다 - Two Sigma, LLC, PDT Partners, DE Shaw, Man AHL, Citadel, Vatic Labs, Point72, Cubist etc.\n",
    "\n",
    "![alt text](https://cdn.sentient.ai/wp-content/uploads/2015/11/Creating_Genes_Slide_01.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Sentient Technologies, an AI company based in San Francisco that also runs a hedge fund, has developed an algorithm that ingests millions of data points to find trading patterns and forecast trends, which enable it to make successful stock trading decisions. \n",
    "- Sentient runs trillions of simulated trading scenarios created from the vast amounts of public data available online. \n",
    "- Squeeze 1,800 days of trading into a few minutes. \n",
    "- Successful trading strategies, which it calls “genes,” are then tested in live trading, where they evolve autonomously as they gain experience.\n",
    "\n",
    "![alt text](https://s3.fintastico.com/media/CACHE/images/numerai-screenshot_756/507ca3ac16b727303ec3f180bd343adf.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Numerai uses artificial intelligence to make trading decisions.\n",
    "- Instead of developing the algorithms themselves, they’ve outsourced the task to thousands of anonymous data scientists, who compete to create the best algorithms and win cryptocurrency for their efforts. \n",
    "- They share trading data with the scientists in a way that prevents them from replicating the fund’s trades while allowing them to build models for better trades.\n",
    "\n",
    "#### Credit Lending\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/richardharris-feedzai-161117114315/95/using-machine-learning-ai-to-enhance-fraud-detection-21-638.jpg?cb=1479383034 \"Logo Title Text 1\")\n",
    "\n",
    "- Machine learning algorithms can be trained on millions of examples of consumer data (age, job, marital status, etc…) and financial lending or insurance results (did this person default, pay back the loan on time, get in a car accident, etc…?).\n",
    "- Trends can be continuously analyzed to detect trends that might influence lending and insuring into the future (are more and more young people in a certain state getting in car accidents? Are there increasing rates of default among a specific demographic population over the last 15 years?\n",
    "- Traditional systems relied on historical data like transaction history, credit history and income growth over years to understand the risk associated with every loan extended. \n",
    "- This results in inconsistent estimates as historical data is not always an accurate standard to predict future behavior.\n",
    "- Machine learning allows analysis of real-time data of recent transactions, market conditions and even latest news to identify potential risks in offering credit. \n",
    "- With the help of predictive analytics, an ML algorithm can analyze petabytes of data to understand micro activities and assess the behavior of parties to identify a possible fraud. \n",
    "- This is something impossible for human investors to perform manually.\n",
    "- Zestfinance does this https://www.zestfinance.com/zaml \n",
    "\n",
    "#### Portfolio Management\n",
    "\n",
    "![alt text](https://blogs.thomsonreuters.com/financial-risk/wp-content/uploads/sites/12/2017/12/1-What-wealth-managers-need-to-know-about-AI-12-Dec-17.gif \"Logo Title Text 1\")\n",
    "\n",
    "- The term “robo-advisor” was essentially unheard-of just five years ago, but it is now commonplace in the financial landscape. \n",
    "- These are algorithms built to calibrate a financial portfolio to the goals and risk tolerance of the user.\n",
    "- Users enter their goals (for example, retiring at age 65 with 250,000.00 in savings), age, income, and current financial assets. \n",
    "- The robo-advisor then spreads investments across asset classes and financial instruments in order to reach the user’s goals.\n",
    "-  The system then calibrates to changes in the user’s goals and to real-time changes in the market, aiming always to find the best fit for the user’s original goals. \n",
    "- Robo-advisors have gained significant traction with millennial consumers who don’t need a physical advisor to feel comfortable investing\n",
    "- Similarly, AI-enabled personal finance intelligence applications are helping consumers manage their finances, analyze spending, automate tax form filing, and make financial recommendations with a business model not predicated to generating fees from investments.\n",
    "- Responsive.ai is doing this http://alpha.responsive.ai/ \n",
    "\n",
    "## Theory\n",
    "\n",
    "### Data Points to Use\n",
    "\n",
    "- Tweets about a company (good/bad)\n",
    "- Reddit Posts (good/bad)\n",
    "- News headlines about a company (good/bad)\n",
    "- Past Prices\n",
    "- All sorts of social media, blog posts\n",
    "- All sorts of financial metadata (dividends, financial reports, etc) \n",
    "\n",
    "#### Regression Problem vs Classification Problem? \n",
    "\n",
    "![alt text](https://searchengineland.com/figz/wp-content/seloads/2016/07/class-regress.png \"Logo Title Text 1\")\n",
    "\n",
    "- We can think of it as a regression model, i.e whats the next data point in a time series? \n",
    "- We can also think of it as a classsificiation problem, i.e will the stock go up or down tomorrow? Buy or sell? \n",
    "- If we want to think of it as a regression problem, we can use a single data point to build the line of best fit.\n",
    "- If we want to use multiple data points, we can use numerical data to create a multivariate regression model. \n",
    "- If we want to use a classification model using a single data point, we'd just learn the mapping between the input (tweets, posts, comments on a given day) and the output (good/bad). We would be able to say that for a given day, the majority of the sentiment for a stack was either good or bad. So for every date givem, our algorithm would learn overall whether or not a stock did well or not. Then given a new date, we could classify it as good/bad. \n",
    "- If we want to combine both sentiment and numerical data i.e prices, we would just use the overall sentiment output of a given date (0 or 1) as an additional feature in our numerical dataset. \n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "- A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).\n",
    "\n",
    "![alt text](http://developer.rhino3d.com/images/linear-regression-01.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "prices = datasets.load_boston()\n",
    "\n",
    "# Use only one feature\n",
    "prices_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "prices_X_train = prices_X[:-20]\n",
    "prices_X_test = prices_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "prices_y_train = prices.target[:-20]\n",
    "prices_y_test = prices.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.SupportVectorMachine()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(prices_X_train, prices_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "prices_y_pred = regr.predict(prices_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*6zJ2ZUUPIOC8nhGqTr3yBQ.jpeg  \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/kMLl-TKaEnc/maxresdefault.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets,\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "- A forecast predicts future events.\n",
    "\n",
    "- A reinforcement learning agent optimizes future outcomes.\n",
    "\n",
    "https://doctorj.gitlab.io/sairen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('sairen-v0')\n",
    "for i_episode in xrange(20):\n",
    "    observation = env.reset()\n",
    "    for t in xrange(100):\n",
    "        env.render()\n",
    "        print observation\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print \"Episode finished after {} timesteps\".format(t+1)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
